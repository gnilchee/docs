{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Just a place for me to keep notes. I am just getting started on this. More to come soon. Getting Started See Kubernetes for some notes on Kubernetes RBAC.","title":"Welcome"},{"location":"#welcome","text":"Just a place for me to keep notes. I am just getting started on this. More to come soon.","title":"Welcome"},{"location":"#getting-started","text":"See Kubernetes for some notes on Kubernetes RBAC.","title":"Getting Started"},{"location":"kubernetes/rbac/","text":"Role Based Access Control (RBAC) Assumptions You are familiar with Kubernetes You are familiar with kubectl Many of the examples in this doc assume you are using Microk8s but can be easily modified to work with vanilla kubectl Helpful Links RBAC Overview (Docs) API Concepts (Docs) Configuring Service Accounts (Docs) Reference Documentation accessing Service Account API Tokens (Docs) Restrict User to one Namespace (Blog) Launch A Kubernetes Cluster Quickly (Project) Installing Snap (Docs) Helpful Starter Config Source from Microk8s (Github) Before You Begin Be aware I recommended that you perform all RBAC examples within a throwaway Kubernetes cluster until you become more familiar with it. I recommend using Microk8s to spin up a dev cluster fast. Show me how to setup a kubernetes cluster with RBAC and Microk8s Install latest stable version of Kubernetes via Snap snap install microk8s --classic Install specified channel of Kubernetes via Snap snap install microk8s --classic --channel=1.15/stable How to list available channels of Microk8s in Snap snap info microk8s Enable RBAC in Microk8s microk8s.enable rbac See Microk8s Docs for more information. The Basics There are 4 main components to implementing RBAC in Kubernetes: Role - Define a set of permissions to resources within a single namespace. ClusterRole - Grant similar permissions to Role but scoped to the cluster (i.e. Nodes), across multiple namespaces or against non-resource endpoints. RoleBinding - Grant permissions defined in a role to a user or group of users (or service accounts) within a namespace. ClusterRoleBinding - Same as RoleBinding but cluster-wide. Examples Let's perform some practical exercises leveraging the above components. Create a Service Account and Namespace cat <<EOF | microk8s.kubectl apply -f - apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: v1 kind: ServiceAccount metadata: name: dev-pod-user namespace: dev EOF Note Service Accounts are Namespaced which means a service account must be created for every namespace you plan to leverage them. Although, you can grant cluster permissions to a Service Account it cannot be used outside the namespace it was created in. We will validate this further down. Role Role definition We defined a Role called full-access-to-pods which we will grant access to the pods resource in the core API group ( \"\" ) allowing all ( '*' ) API verbs. Basically granting full access to the /api/v1/pods Kubernetes API within the dev namespace. kind : Role apiVersion : rbac.authorization.k8s.io/v1 metadata : name : full-access-to-pods namespace : dev rules : - apiGroups : - \"\" resources : - pods verbs : - '*' How do I find any of the following on an API resource? If the resource is Namespaced (scoped to a namespace) What API Group it's apart of What Verbs are allowed Resource names, shortnames, api groups, if the resource is namespaced (true/false), kind and allowed verbs are all available via the microk8s.kubectl api-resources -o wide command. Show me how to obtain API Resource details via kubectl $ microk8s.kubectl api-resources -o wide NAME SHORTNAMES APIGROUP NAMESPACED KIND VERBS bindings true Binding [create] componentstatuses cs false ComponentStatus [get list] configmaps cm true ConfigMap [create delete deletecollection get list patch update watch] endpoints ep true Endpoints [create delete deletecollection get list patch update watch] events ev true Event [create delete deletecollection get list patch update watch] limitranges limits true LimitRange [create delete deletecollection get list patch update watch] namespaces ns false Namespace [create delete get list patch update watch] nodes no false Node [create delete deletecollection get list patch update watch] persistentvolumeclaims pvc true PersistentVolumeClaim [create delete deletecollection get list patch update watch] persistentvolumes pv false PersistentVolume [create delete deletecollection get list patch update watch] pods po true Pod [create delete deletecollection get list patch update watch] podtemplates true PodTemplate [create delete deletecollection get list patch update watch] [snipped] horizontalpodautoscalers hpa autoscaling true HorizontalPodAutoscaler [create delete deletecollection get list patch update watch] cronjobs cj batch true CronJob [create delete deletecollection get list patch update watch] jobs batch true Job [create delete deletecollection get list patch update watch] certificatesigningrequests csr certificates.k8s.io false CertificateSigningRequest [create delete deletecollection get list patch update watch] leases coordination.k8s.io true Lease [create delete deletecollection get list patch update watch] endpointslices discovery.k8s.io true EndpointSlice [create delete deletecollection get list patch update watch] events ev events.k8s.io true Event [create delete deletecollection get list patch update watch] ingresses ing extensions true Ingress [create delete deletecollection get list patch update watch] ingresses ing networking.k8s.io true Ingress [create delete deletecollection get list patch update watch] networkpolicies netpol networking.k8s.io true NetworkPolicy [create delete deletecollection get list patch update watch] runtimeclasses node.k8s.io false RuntimeClass [create delete deletecollection get list patch update watch] poddisruptionbudgets pdb policy true PodDisruptionBudget [create delete deletecollection get list patch update watch] podsecuritypolicies psp policy false PodSecurityPolicy [create delete deletecollection get list patch update watch] clusterrolebindings rbac.authorization.k8s.io false ClusterRoleBinding [create delete deletecollection get list patch update watch] [snipped] Apply the Role cat <<EOF | microk8s.kubectl apply -f - kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: full-access-to-pods namespace: dev rules: - apiGroups: - \"\" resources: - pods verbs: - '*' EOF RoleBinding Now that we created a new namespace called dev , a service account called dev-pod-user and a role called full-access-to-pods and associate them together with a RoleBinding. RoleBinding definition Let's define a RoleBinding called full-access-to-pods-role-binding which we will grant service account dev-pod-user access to the full-access-to-pods role. apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : full-access-to-pods-role-binding namespace : dev roleRef : apiGroup : rbac.authorization.k8s.io kind : Role name : full-access-to-pods subjects : - kind : ServiceAccount name : dev-pod-user See Binding Documentation for more information. Now apply the RoleBinding cat <<EOF | microk8s.kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: full-access-to-pods-role-binding namespace: dev roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: full-access-to-pods subjects: - kind: ServiceAccount name: dev-pod-user EOF Tldr In order to create a service account you need to target an existing namespace or create a new one. A role can be created without a specific service account in mind but also need to target an existing namespace or create a new one. When creating a RoleBinding you will need to target a namespace, an existing role (roleRef) in that namespace and a user, group, or service account (subject). Using our new role Now let's add a sample deployment to the dev namespace based on Istio's httpbin sample application. Deploy a reference pod The sample application deployment will launch a single pod with a python based application which will use the default service account in the dev namespace. Refer to Kubernetes documentation to get more information on the default behavior when launching a pod. cat <<EOF | microk8s.kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: httpbin namespace: dev spec: replicas: 1 selector: matchLabels: app: httpbin version: v1 template: metadata: labels: app: httpbin version: v1 spec: containers: - image: docker.io/kennethreitz/httpbin imagePullPolicy: IfNotPresent name: httpbin ports: - containerPort: 80 EOF Now confirm the Service Account used for the Pod Below we confirmed that the deployment launched the pod with the default service account. $ microk8s.kubectl get pod httpbin-768b999cb5-5c4cl -n dev -o yaml | grep serviceAccountName serviceAccountName: default Also note that Kubernetes automatically mounts the default token into the pod $ microk8s.kubectl get pod httpbin-768b999cb5-5c4cl -n dev -o yaml apiVersion: v1 kind: Pod metadata: [snipped] name: httpbin-768b999cb5-5c4cl [snipped] volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: default-token-nlzgt readOnly: true Exec into the httpbin container and see what data gets mounted in as a result root@httpbin-768b999cb5-5c4cl:/# ls -l /var/run/secrets/kubernetes.io/serviceaccount total 0 lrwxrwxrwx 1 root root 13 Jan 3 04:08 ca.crt -> ..data/ca.crt lrwxrwxrwx 1 root root 16 Jan 3 04:08 namespace -> ..data/namespace lrwxrwxrwx 1 root root 12 Jan 3 04:08 token -> ..data/token root@httpbin-768b999cb5-5c4cl:/# cat /var/run/secrets/kubernetes.io/serviceaccount/namespace ; echo dev root@httpbin-768b999cb5-5c4cl:/# cat /var/run/secrets/kubernetes.io/serviceaccount/token ; echo eyJhbGciOiJSUzI1NiIsImtpZCI6Ikxh...EsHorrcKBTnSa10OORjOrFpg How can we leverage the service account We now know that Kubernetes automatically assigns a service account and mounts in the token and namespace which can be leveraged by tools such as kubectl and Kubernetes client libraries. Let's see how this can be useful and add kubectl to the container and attempt to perform some commands and see if anything special is needed to get it to work. Issue commands from within the Pod container First we download kubectl binary down to the Microk8s instance $ curl -s -LO https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubectl $ chmod +x kubectl $ ls kubectl snap Now we copy the kubectl into the Pod's container $ microk8s.kubectl get pods -n dev NAME READY STATUS RESTARTS AGE httpbin-768b999cb5-5c4cl 1/1 Running 0 44m $ microk8s.kubectl cp kubectl dev/httpbin-768b999cb5-5c4cl:/tmp/kubectl $ Finally, let's exec into the container and run the /tmp/kubectl get pods command $ microk8s.kubectl exec -it httpbin-768b999cb5-5c4cl -n dev -- /bin/bash root@httpbin-768b999cb5-5c4cl:/# /tmp/kubectl get pods Error from server (Forbidden): pods is forbidden: User \"system:serviceaccount:dev:default\" cannot list resource \"pods\" in API group \"\" in the namespace \"dev\" Review Examining what we know so far is that by default when we don't define a service account Kubernetes will automatically assign one and mount in the account's token and the namespace of the pod which we can use a tool like kubectl to execute commands. Looking specifically at the above example we can see that by running /tmp/kubectl get pods it can determine the pod's namespace and token to use by looking in that directory. Question How does kubectl know what endpoint to issue calls against to hit the Kubernetes API? It turns out Kubernetes injects env vars into the pod root@httpbin-768b999cb5-5c4cl:/# env | grep -i kubernetes KUBERNETES_PORT_443_TCP_PROTO=tcp KUBERNETES_PORT_443_TCP_ADDR=10.152.183.1 KUBERNETES_PORT=tcp://10.152.183.1:443 KUBERNETES_SERVICE_PORT_HTTPS=443 KUBERNETES_PORT_443_TCP_PORT=443 KUBERNETES_PORT_443_TCP=tcp://10.152.183.1:443 KUBERNETES_SERVICE_PORT=443 KUBERNETES_SERVICE_HOST=10.152.183.1 If we unset the KUBERNETES_SERVICE_HOST var we confirm it breaks kubectl root@httpbin-768b999cb5-5c4cl:/# unset KUBERNETES_SERVICE_HOST root@httpbin-768b999cb5-5c4cl:/# /tmp/kubectl get pods The connection to the server localhost:8080 was refused - did you specify the right host or port? Deploy a pod that uses our new role Since we now know what happens when we launch a pod with the default service account let's launch a new pod that will use the dev-pod-user service account and the full-access-to-pods role we created earlier. We will launch a new deployment called deb-test and assign the new service account dev-pod-user into the dev namespace. cat <<EOF | microk8s.kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: deb-test namespace: dev spec: replicas: 1 selector: matchLabels: app: deb-test template: metadata: labels: app: deb-test spec: serviceAccountName: dev-pod-user containers: - image: debian:latest imagePullPolicy: IfNotPresent name: deb-test command: - sleep - \"3600\" restartPolicy: Always EOF Now confirm the Service Account used for the new Pod We first confirm the new deployment launched the pod with the dev-pod-user service account. $ microk8s.kubectl get pod deb-test-669c58cc9d-99gz4 -n dev -o yaml | grep serviceAccountName serviceAccountName: dev-pod-user Also confirm that Kubernetes mounts the dev-pod-user token into the pod $ microk8s.kubectl get pod deb-test-669c58cc9d-99gz4 -n dev -o yaml apiVersion: v1 kind: Pod metadata: [snipped] name: deb-test-669c58cc9d-99gz4 namespace: dev [snipped] volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: dev-pod-user-token-mngkj readOnly: true Now we leverage the new service account Great! We confirmed that with our new deployment Kubernetes assigned the dev-pod-user service account and mounted in the token and namespace as it did with our reference deployment. Let's repeat the test from before but it will now use our new role. Issue commands from within the new Pod container Since we already downloaded the kubectl binary we just need to copy it into the new container $ microk8s.kubectl get pods -n dev | grep deb-test deb-test-669c58cc9d-99gz4 1/1 Running 0 10m $ microk8s.kubectl cp kubectl dev/deb-test-669c58cc9d-99gz4:/tmp/kubectl $ Now let's exec into the deb-test container and run /tmp/kubectl get pods again and see if we still get a permission error $ microk8s.kubectl exec -it deb-test-669c58cc9d-99gz4 -n dev -- /bin/bash root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl get pods NAME READY STATUS RESTARTS AGE deb-test-669c58cc9d-99gz4 1/1 Running 0 13m httpbin-768b999cb5-5c4cl 1/1 Running 0 111m Let's also try to delete another pod in the dev namespace and confirm that also works root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl delete pod httpbin-768b999cb5-5c4cl pod \"httpbin-768b999cb5-5c4cl\" deleted root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl get pods NAME READY STATUS RESTARTS AGE deb-test-669c58cc9d-99gz4 1/1 Running 0 23m httpbin-768b999cb5-dtwhd 1/1 Running 0 13s \ud83c\udf89\ud83c\udf89\ud83c\udf89 Success! We are now able to get and delete pods in the dev namespace. Our role works as expected. We confirmed that by using our new service account and role we created earlier we have full access to the pod API in the dev namespace. Like we mentioned in the The Basics section a Role only applies to the namespace it was created in. Let's attempt to get pods again but across all namespaces. Question What happens across namespaces? We get a different permission error root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl get pods --all-namespaces Error from server (Forbidden): pods is forbidden: User \"system:serviceaccount:dev:dev-pod-user\" cannot list resource \"pods\" in API group \"\" at the cluster scope \ud83d\udd25\ud83d\udd25\ud83d\udd25 It fails with another permission issue but we expected this one. Review As expected, we get a permission error in the above example saying that you cannot list resource \"pods\" at the cluster scope in the core API group. Basically, in order to list pods outside the dev namespace we will need to create a ClusterRole (cluster scoped). ClusterRole TODO","title":"RBAC"},{"location":"kubernetes/rbac/#role-based-access-control-rbac","text":"","title":"Role Based Access Control (RBAC)"},{"location":"kubernetes/rbac/#assumptions","text":"You are familiar with Kubernetes You are familiar with kubectl Many of the examples in this doc assume you are using Microk8s but can be easily modified to work with vanilla kubectl","title":"Assumptions"},{"location":"kubernetes/rbac/#helpful-links","text":"RBAC Overview (Docs) API Concepts (Docs) Configuring Service Accounts (Docs) Reference Documentation accessing Service Account API Tokens (Docs) Restrict User to one Namespace (Blog) Launch A Kubernetes Cluster Quickly (Project) Installing Snap (Docs) Helpful Starter Config Source from Microk8s (Github)","title":"Helpful Links"},{"location":"kubernetes/rbac/#before-you-begin","text":"Be aware I recommended that you perform all RBAC examples within a throwaway Kubernetes cluster until you become more familiar with it. I recommend using Microk8s to spin up a dev cluster fast. Show me how to setup a kubernetes cluster with RBAC and Microk8s","title":"Before You Begin"},{"location":"kubernetes/rbac/#install-latest-stable-version-of-kubernetes-via-snap","text":"snap install microk8s --classic","title":"Install latest stable version of Kubernetes via Snap"},{"location":"kubernetes/rbac/#install-specified-channel-of-kubernetes-via-snap","text":"snap install microk8s --classic --channel=1.15/stable","title":"Install specified channel of Kubernetes via Snap"},{"location":"kubernetes/rbac/#how-to-list-available-channels-of-microk8s-in-snap","text":"snap info microk8s","title":"How to list available channels of Microk8s in Snap"},{"location":"kubernetes/rbac/#enable-rbac-in-microk8s","text":"microk8s.enable rbac See Microk8s Docs for more information.","title":"Enable RBAC in Microk8s"},{"location":"kubernetes/rbac/#the-basics","text":"There are 4 main components to implementing RBAC in Kubernetes: Role - Define a set of permissions to resources within a single namespace. ClusterRole - Grant similar permissions to Role but scoped to the cluster (i.e. Nodes), across multiple namespaces or against non-resource endpoints. RoleBinding - Grant permissions defined in a role to a user or group of users (or service accounts) within a namespace. ClusterRoleBinding - Same as RoleBinding but cluster-wide.","title":"The Basics"},{"location":"kubernetes/rbac/#examples","text":"Let's perform some practical exercises leveraging the above components.","title":"Examples"},{"location":"kubernetes/rbac/#create-a-service-account-and-namespace","text":"cat <<EOF | microk8s.kubectl apply -f - apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: v1 kind: ServiceAccount metadata: name: dev-pod-user namespace: dev EOF Note Service Accounts are Namespaced which means a service account must be created for every namespace you plan to leverage them. Although, you can grant cluster permissions to a Service Account it cannot be used outside the namespace it was created in. We will validate this further down.","title":"Create a Service Account and Namespace"},{"location":"kubernetes/rbac/#role","text":"Role definition We defined a Role called full-access-to-pods which we will grant access to the pods resource in the core API group ( \"\" ) allowing all ( '*' ) API verbs. Basically granting full access to the /api/v1/pods Kubernetes API within the dev namespace. kind : Role apiVersion : rbac.authorization.k8s.io/v1 metadata : name : full-access-to-pods namespace : dev rules : - apiGroups : - \"\" resources : - pods verbs : - '*'","title":"Role"},{"location":"kubernetes/rbac/#how-do-i-find-any-of-the-following-on-an-api-resource","text":"If the resource is Namespaced (scoped to a namespace) What API Group it's apart of What Verbs are allowed Resource names, shortnames, api groups, if the resource is namespaced (true/false), kind and allowed verbs are all available via the microk8s.kubectl api-resources -o wide command. Show me how to obtain API Resource details via kubectl $ microk8s.kubectl api-resources -o wide NAME SHORTNAMES APIGROUP NAMESPACED KIND VERBS bindings true Binding [create] componentstatuses cs false ComponentStatus [get list] configmaps cm true ConfigMap [create delete deletecollection get list patch update watch] endpoints ep true Endpoints [create delete deletecollection get list patch update watch] events ev true Event [create delete deletecollection get list patch update watch] limitranges limits true LimitRange [create delete deletecollection get list patch update watch] namespaces ns false Namespace [create delete get list patch update watch] nodes no false Node [create delete deletecollection get list patch update watch] persistentvolumeclaims pvc true PersistentVolumeClaim [create delete deletecollection get list patch update watch] persistentvolumes pv false PersistentVolume [create delete deletecollection get list patch update watch] pods po true Pod [create delete deletecollection get list patch update watch] podtemplates true PodTemplate [create delete deletecollection get list patch update watch] [snipped] horizontalpodautoscalers hpa autoscaling true HorizontalPodAutoscaler [create delete deletecollection get list patch update watch] cronjobs cj batch true CronJob [create delete deletecollection get list patch update watch] jobs batch true Job [create delete deletecollection get list patch update watch] certificatesigningrequests csr certificates.k8s.io false CertificateSigningRequest [create delete deletecollection get list patch update watch] leases coordination.k8s.io true Lease [create delete deletecollection get list patch update watch] endpointslices discovery.k8s.io true EndpointSlice [create delete deletecollection get list patch update watch] events ev events.k8s.io true Event [create delete deletecollection get list patch update watch] ingresses ing extensions true Ingress [create delete deletecollection get list patch update watch] ingresses ing networking.k8s.io true Ingress [create delete deletecollection get list patch update watch] networkpolicies netpol networking.k8s.io true NetworkPolicy [create delete deletecollection get list patch update watch] runtimeclasses node.k8s.io false RuntimeClass [create delete deletecollection get list patch update watch] poddisruptionbudgets pdb policy true PodDisruptionBudget [create delete deletecollection get list patch update watch] podsecuritypolicies psp policy false PodSecurityPolicy [create delete deletecollection get list patch update watch] clusterrolebindings rbac.authorization.k8s.io false ClusterRoleBinding [create delete deletecollection get list patch update watch] [snipped]","title":"How do I find any of the following on an API resource?"},{"location":"kubernetes/rbac/#apply-the-role","text":"cat <<EOF | microk8s.kubectl apply -f - kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: full-access-to-pods namespace: dev rules: - apiGroups: - \"\" resources: - pods verbs: - '*' EOF","title":"Apply the Role"},{"location":"kubernetes/rbac/#rolebinding","text":"Now that we created a new namespace called dev , a service account called dev-pod-user and a role called full-access-to-pods and associate them together with a RoleBinding. RoleBinding definition Let's define a RoleBinding called full-access-to-pods-role-binding which we will grant service account dev-pod-user access to the full-access-to-pods role. apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : full-access-to-pods-role-binding namespace : dev roleRef : apiGroup : rbac.authorization.k8s.io kind : Role name : full-access-to-pods subjects : - kind : ServiceAccount name : dev-pod-user See Binding Documentation for more information.","title":"RoleBinding"},{"location":"kubernetes/rbac/#now-apply-the-rolebinding","text":"cat <<EOF | microk8s.kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: full-access-to-pods-role-binding namespace: dev roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: full-access-to-pods subjects: - kind: ServiceAccount name: dev-pod-user EOF Tldr In order to create a service account you need to target an existing namespace or create a new one. A role can be created without a specific service account in mind but also need to target an existing namespace or create a new one. When creating a RoleBinding you will need to target a namespace, an existing role (roleRef) in that namespace and a user, group, or service account (subject).","title":"Now apply the RoleBinding"},{"location":"kubernetes/rbac/#using-our-new-role","text":"Now let's add a sample deployment to the dev namespace based on Istio's httpbin sample application.","title":"Using our new role"},{"location":"kubernetes/rbac/#deploy-a-reference-pod","text":"The sample application deployment will launch a single pod with a python based application which will use the default service account in the dev namespace. Refer to Kubernetes documentation to get more information on the default behavior when launching a pod. cat <<EOF | microk8s.kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: httpbin namespace: dev spec: replicas: 1 selector: matchLabels: app: httpbin version: v1 template: metadata: labels: app: httpbin version: v1 spec: containers: - image: docker.io/kennethreitz/httpbin imagePullPolicy: IfNotPresent name: httpbin ports: - containerPort: 80 EOF Now confirm the Service Account used for the Pod Below we confirmed that the deployment launched the pod with the default service account. $ microk8s.kubectl get pod httpbin-768b999cb5-5c4cl -n dev -o yaml | grep serviceAccountName serviceAccountName: default Also note that Kubernetes automatically mounts the default token into the pod $ microk8s.kubectl get pod httpbin-768b999cb5-5c4cl -n dev -o yaml apiVersion: v1 kind: Pod metadata: [snipped] name: httpbin-768b999cb5-5c4cl [snipped] volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: default-token-nlzgt readOnly: true Exec into the httpbin container and see what data gets mounted in as a result root@httpbin-768b999cb5-5c4cl:/# ls -l /var/run/secrets/kubernetes.io/serviceaccount total 0 lrwxrwxrwx 1 root root 13 Jan 3 04:08 ca.crt -> ..data/ca.crt lrwxrwxrwx 1 root root 16 Jan 3 04:08 namespace -> ..data/namespace lrwxrwxrwx 1 root root 12 Jan 3 04:08 token -> ..data/token root@httpbin-768b999cb5-5c4cl:/# cat /var/run/secrets/kubernetes.io/serviceaccount/namespace ; echo dev root@httpbin-768b999cb5-5c4cl:/# cat /var/run/secrets/kubernetes.io/serviceaccount/token ; echo eyJhbGciOiJSUzI1NiIsImtpZCI6Ikxh...EsHorrcKBTnSa10OORjOrFpg","title":"Deploy a reference pod"},{"location":"kubernetes/rbac/#how-can-we-leverage-the-service-account","text":"We now know that Kubernetes automatically assigns a service account and mounts in the token and namespace which can be leveraged by tools such as kubectl and Kubernetes client libraries. Let's see how this can be useful and add kubectl to the container and attempt to perform some commands and see if anything special is needed to get it to work. Issue commands from within the Pod container First we download kubectl binary down to the Microk8s instance $ curl -s -LO https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubectl $ chmod +x kubectl $ ls kubectl snap Now we copy the kubectl into the Pod's container $ microk8s.kubectl get pods -n dev NAME READY STATUS RESTARTS AGE httpbin-768b999cb5-5c4cl 1/1 Running 0 44m $ microk8s.kubectl cp kubectl dev/httpbin-768b999cb5-5c4cl:/tmp/kubectl $ Finally, let's exec into the container and run the /tmp/kubectl get pods command $ microk8s.kubectl exec -it httpbin-768b999cb5-5c4cl -n dev -- /bin/bash root@httpbin-768b999cb5-5c4cl:/# /tmp/kubectl get pods Error from server (Forbidden): pods is forbidden: User \"system:serviceaccount:dev:default\" cannot list resource \"pods\" in API group \"\" in the namespace \"dev\"","title":"How can we leverage the service account"},{"location":"kubernetes/rbac/#review","text":"Examining what we know so far is that by default when we don't define a service account Kubernetes will automatically assign one and mount in the account's token and the namespace of the pod which we can use a tool like kubectl to execute commands. Looking specifically at the above example we can see that by running /tmp/kubectl get pods it can determine the pod's namespace and token to use by looking in that directory. Question How does kubectl know what endpoint to issue calls against to hit the Kubernetes API? It turns out Kubernetes injects env vars into the pod root@httpbin-768b999cb5-5c4cl:/# env | grep -i kubernetes KUBERNETES_PORT_443_TCP_PROTO=tcp KUBERNETES_PORT_443_TCP_ADDR=10.152.183.1 KUBERNETES_PORT=tcp://10.152.183.1:443 KUBERNETES_SERVICE_PORT_HTTPS=443 KUBERNETES_PORT_443_TCP_PORT=443 KUBERNETES_PORT_443_TCP=tcp://10.152.183.1:443 KUBERNETES_SERVICE_PORT=443 KUBERNETES_SERVICE_HOST=10.152.183.1 If we unset the KUBERNETES_SERVICE_HOST var we confirm it breaks kubectl root@httpbin-768b999cb5-5c4cl:/# unset KUBERNETES_SERVICE_HOST root@httpbin-768b999cb5-5c4cl:/# /tmp/kubectl get pods The connection to the server localhost:8080 was refused - did you specify the right host or port?","title":"Review"},{"location":"kubernetes/rbac/#deploy-a-pod-that-uses-our-new-role","text":"Since we now know what happens when we launch a pod with the default service account let's launch a new pod that will use the dev-pod-user service account and the full-access-to-pods role we created earlier. We will launch a new deployment called deb-test and assign the new service account dev-pod-user into the dev namespace. cat <<EOF | microk8s.kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: deb-test namespace: dev spec: replicas: 1 selector: matchLabels: app: deb-test template: metadata: labels: app: deb-test spec: serviceAccountName: dev-pod-user containers: - image: debian:latest imagePullPolicy: IfNotPresent name: deb-test command: - sleep - \"3600\" restartPolicy: Always EOF Now confirm the Service Account used for the new Pod We first confirm the new deployment launched the pod with the dev-pod-user service account. $ microk8s.kubectl get pod deb-test-669c58cc9d-99gz4 -n dev -o yaml | grep serviceAccountName serviceAccountName: dev-pod-user Also confirm that Kubernetes mounts the dev-pod-user token into the pod $ microk8s.kubectl get pod deb-test-669c58cc9d-99gz4 -n dev -o yaml apiVersion: v1 kind: Pod metadata: [snipped] name: deb-test-669c58cc9d-99gz4 namespace: dev [snipped] volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: dev-pod-user-token-mngkj readOnly: true","title":"Deploy a pod that uses our new role"},{"location":"kubernetes/rbac/#now-we-leverage-the-new-service-account","text":"Great! We confirmed that with our new deployment Kubernetes assigned the dev-pod-user service account and mounted in the token and namespace as it did with our reference deployment. Let's repeat the test from before but it will now use our new role. Issue commands from within the new Pod container Since we already downloaded the kubectl binary we just need to copy it into the new container $ microk8s.kubectl get pods -n dev | grep deb-test deb-test-669c58cc9d-99gz4 1/1 Running 0 10m $ microk8s.kubectl cp kubectl dev/deb-test-669c58cc9d-99gz4:/tmp/kubectl $ Now let's exec into the deb-test container and run /tmp/kubectl get pods again and see if we still get a permission error $ microk8s.kubectl exec -it deb-test-669c58cc9d-99gz4 -n dev -- /bin/bash root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl get pods NAME READY STATUS RESTARTS AGE deb-test-669c58cc9d-99gz4 1/1 Running 0 13m httpbin-768b999cb5-5c4cl 1/1 Running 0 111m Let's also try to delete another pod in the dev namespace and confirm that also works root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl delete pod httpbin-768b999cb5-5c4cl pod \"httpbin-768b999cb5-5c4cl\" deleted root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl get pods NAME READY STATUS RESTARTS AGE deb-test-669c58cc9d-99gz4 1/1 Running 0 23m httpbin-768b999cb5-dtwhd 1/1 Running 0 13s \ud83c\udf89\ud83c\udf89\ud83c\udf89 Success! We are now able to get and delete pods in the dev namespace. Our role works as expected. We confirmed that by using our new service account and role we created earlier we have full access to the pod API in the dev namespace. Like we mentioned in the The Basics section a Role only applies to the namespace it was created in. Let's attempt to get pods again but across all namespaces. Question What happens across namespaces? We get a different permission error root@deb-test-669c58cc9d-99gz4:/# /tmp/kubectl get pods --all-namespaces Error from server (Forbidden): pods is forbidden: User \"system:serviceaccount:dev:dev-pod-user\" cannot list resource \"pods\" in API group \"\" at the cluster scope \ud83d\udd25\ud83d\udd25\ud83d\udd25 It fails with another permission issue but we expected this one.","title":"Now we leverage the new service account"},{"location":"kubernetes/rbac/#review_1","text":"As expected, we get a permission error in the above example saying that you cannot list resource \"pods\" at the cluster scope in the core API group. Basically, in order to list pods outside the dev namespace we will need to create a ClusterRole (cluster scoped).","title":"Review"},{"location":"kubernetes/rbac/#clusterrole","text":"TODO","title":"ClusterRole"}]}